[package]
name = "candle-mi"
version = "0.0.1"
edition = "2024"
authors = ["Eric Jacopin"]
description = "Mechanistic interpretability for language models in Rust, built on candle"
license = "MIT OR Apache-2.0"
repository = "https://github.com/PCfVW/candle-mi"
keywords = ["interpretability", "transformers", "mechanistic", "candle", "rust"]
categories = ["science", "machine-learning"]
rust-version = "1.85"

[dependencies]
# Candle ML framework (pinned to 0.9.x per design/candle-version.md)
candle-core = "0.9"
candle-nn = "0.9"

# HuggingFace integration
tokenizers = "0.21"
hf-hub = "0.4"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
safetensors = "0.4"

# Error handling (typed MIError per design/error-handling.md)
thiserror = "2"
anyhow = "1.0"

# Random number generation
rand = "0.8"

# Statistics
statrs = "0.17"

# Logging
tracing = "0.1"

# Optional: probing
ndarray = { version = "0.15", optional = true }
linfa = { version = "0.7", optional = true }
linfa-logistic = { version = "0.7", optional = true }

[dev-dependencies]
tempfile = "3.10"

[features]
default = ["cuda", "transformer"]
cuda = ["candle-core/cuda", "candle-nn/cuda"]
metal = ["candle-core/metal", "candle-nn/metal"]
transformer = []
rwkv = []
rwkv-tokenizer = []
clt = []
sae = []
probing = ["linfa", "linfa-logistic", "ndarray"]

[profile.release]
lto = true
codegen-units = 1
opt-level = 3

[profile.dev]
opt-level = 1
